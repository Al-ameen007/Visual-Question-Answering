{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLIP-VQA Inference Playground\n",
    "\n",
    "Compare predictions between base BLIP model and fine-tuned model on VizWiz dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import BlipForQuestionAnswering, AutoProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "print(\"Loading base model...\")\n",
    "base_model = BlipForQuestionAnswering.from_pretrained('Salesforce/blip-vqa-base')\n",
    "base_processor = AutoProcessor.from_pretrained('Salesforce/blip-vqa-base')\n",
    "base_model.to(device)\n",
    "base_model.eval()\n",
    "\n",
    "print(\"Loading trained model...\")\n",
    "trained_model = BlipForQuestionAnswering.from_pretrained('MohammadAlameenArtan/BLIP_Model_VizWiz')\n",
    "trained_processor = AutoProcessor.from_pretrained('MohammadAlameenArtan/BLIP_Model_VizWiz')\n",
    "trained_model.to(device)\n",
    "trained_model.eval()\n",
    "\n",
    "print(\"Models loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_source):\n",
    "    if image_source.startswith('http://') or image_source.startswith('https://'):\n",
    "        response = requests.get(image_source)\n",
    "        image = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "    else:\n",
    "        image = Image.open(image_source).convert('RGB')\n",
    "    return image\n",
    "\n",
    "\n",
    "def predict_answer(image, question, model, processor):\n",
    "    inputs = processor(images=image, text=question, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs)\n",
    "    \n",
    "    answer = processor.decode(outputs[0], skip_special_tokens=True)\n",
    "    return answer\n",
    "\n",
    "\n",
    "def visualize_comparison(image, question, base_answer, trained_answer, correct_answer=None):\n",
    "    fig, ax = plt.subplots(figsize=(10, 12))\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    if correct_answer:\n",
    "        color_base = 'green' if base_answer.lower() == correct_answer.lower() else 'red'\n",
    "        color_trained = 'green' if trained_answer.lower() == correct_answer.lower() else 'red'\n",
    "    else:\n",
    "        color_base = 'blue'\n",
    "        color_trained = 'orange'\n",
    "    \n",
    "    plt.text(0.5, -0.08, f\"Question: {question}\", \n",
    "             fontsize=14, ha='center', weight='bold', transform=ax.transAxes)\n",
    "    plt.text(0.5, -0.13, f\"Base Model: {base_answer}\", \n",
    "             fontsize=13, color=color_base, ha='center', transform=ax.transAxes)\n",
    "    plt.text(0.5, -0.18, f\"Trained Model: {trained_answer}\", \n",
    "             fontsize=13, color=color_trained, ha='center', transform=ax.transAxes)\n",
    "    \n",
    "    if correct_answer:\n",
    "        plt.text(0.5, -0.23, f\"Correct Answer: {correct_answer}\", \n",
    "                 fontsize=13, ha='center', weight='bold', transform=ax.transAxes)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def compare_models(image_source, question, correct_answer=None):\n",
    "    print(f\"Loading image from: {image_source}\")\n",
    "    image = load_image(image_source)\n",
    "    \n",
    "    print(f\"\\nQuestion: {question}\")\n",
    "    print(\"\\nGenerating answers...\")\n",
    "    \n",
    "    base_answer = predict_answer(image, question, base_model, base_processor)\n",
    "    trained_answer = predict_answer(image, question, trained_model, trained_processor)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Base Model Answer:    {base_answer}\")\n",
    "    print(f\"Trained Model Answer: {trained_answer}\")\n",
    "    \n",
    "    if correct_answer:\n",
    "        print(f\"Correct Answer:       {correct_answer}\")\n",
    "        print(f\"\\nBase Model Correct:    {base_answer.lower() == correct_answer.lower()}\")\n",
    "        print(f\"Trained Model Correct: {trained_answer.lower() == correct_answer.lower()}\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    visualize_comparison(image, question, base_answer, trained_answer, correct_answer)\n",
    "    \n",
    "    return base_answer, trained_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Car and Planes\n",
    "\n",
    "From the original notebook example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = 'https://i.pinimg.com/564x/ca/92/40/ca9240d151ac9f6a65ec5514c860c28f.jpg'\n",
    "question = 'what vehicles are in the picture'\n",
    "correct_answer = 'car and two planes'\n",
    "\n",
    "base_ans, trained_ans = compare_models(image_url, question, correct_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Your Custom Test\n",
    "\n",
    "Try your own image and question!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_source = 'https://example.com/your-image.jpg'\n",
    "question = 'what is in the image?'\n",
    "correct_answer = None\n",
    "\n",
    "base_ans, trained_ans = compare_models(image_source, question, correct_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Local Image\n",
    "\n",
    "Test with a local image file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = './path/to/your/image.jpg'\n",
    "question = 'describe this image'\n",
    "correct_answer = None\n",
    "\n",
    "base_ans, trained_ans = compare_models(image_path, question, correct_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Testing\n",
    "\n",
    "Test multiple images at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = [\n",
    "    {\n",
    "        'image': 'https://example.com/image1.jpg',\n",
    "        'question': 'what color is the car?',\n",
    "        'answer': 'red'\n",
    "    },\n",
    "    {\n",
    "        'image': 'https://example.com/image2.jpg',\n",
    "        'question': 'how many people are there?',\n",
    "        'answer': '3'\n",
    "    },\n",
    "]\n",
    "\n",
    "results = []\n",
    "for i, test in enumerate(test_cases):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Test Case {i+1}/{len(test_cases)}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    base_ans, trained_ans = compare_models(\n",
    "        test['image'], \n",
    "        test['question'], \n",
    "        test['answer']\n",
    "    )\n",
    "    \n",
    "    results.append({\n",
    "        'question': test['question'],\n",
    "        'base': base_ans,\n",
    "        'trained': trained_ans,\n",
    "        'correct': test['answer']\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Playground\n",
    "\n",
    "Run this cell and modify the variables to test different scenarios!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_URL = 'https://i.pinimg.com/564x/ca/92/40/ca9240d151ac9f6a65ec5514c860c28f.jpg'\n",
    "QUESTION = 'what vehicles are in the picture'\n",
    "CORRECT_ANSWER = 'car and two planes'\n",
    "\n",
    "compare_models(IMAGE_URL, QUESTION, CORRECT_ANSWER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics\n",
    "\n",
    "If you ran batch testing, see overall performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'results' in locals():\n",
    "    base_correct = sum(1 for r in results if r['base'].lower() == r['correct'].lower())\n",
    "    trained_correct = sum(1 for r in results if r['trained'].lower() == r['correct'].lower())\n",
    "    total = len(results)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SUMMARY STATISTICS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total test cases: {total}\")\n",
    "    print(f\"\\nBase Model:\")\n",
    "    print(f\"  Correct: {base_correct}/{total} ({100*base_correct/total:.1f}%)\")\n",
    "    print(f\"\\nTrained Model:\")\n",
    "    print(f\"  Correct: {trained_correct}/{total} ({100*trained_correct/total:.1f}%)\")\n",
    "    print(f\"\\nImprovement: {trained_correct - base_correct} questions\")\n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    print(\"No batch testing results available. Run the batch testing cell first!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
